{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up a data processing worflow for NetCDF in WINGS\n",
    "\n",
    "This Jupyter Notebook walks through the necessary steps to set up a data processing workflow for NetCDF files to files needed by [TOPOFLOW](https://github.com/peckhams/topoflow) in [WINGS](http://www.wings-workflows.org). The data used in this example and necessary processing steps are described [here](https://github.com/khider/netCDFTutorial/blob/master/TOPOFLOW%20var%20example.ipynb).\n",
    "\n",
    "This Notebook is set up so that each cell represents a workflow component. The text lists the necessary data and parameters inputs for each of the component, the outputs, and the assumptions.\n",
    "\n",
    "Table of Contents\n",
    "1. [openNetCDF](#opennetcdf)\n",
    "2. [adjustTime](#adjusttime)\n",
    "3. [selectVar](#selectVar)\n",
    "4. [calculateRH](#calculateRH)\n",
    "5. [calculateWind](#calculateWind)\n",
    "6. [amountToRate](#amount)\n",
    "7. [completeCheck](#complete)\n",
    "8. [adjustUnits](#units)\n",
    "9. [adjustformat](#format)\n",
    "\n",
    "## <a name='opennetcdf'> openNetCDF </a>\n",
    "\n",
    "This component open the NetCDF file and dumps the content into a Python dictionary, exposing the metadata in the process.\n",
    "\n",
    "- Inputs: NetCDF files\n",
    "- Outputs: Pickled file\n",
    "- Parameters: None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from netCDF4 import MFDataset\n",
    "import pickle\n",
    "\n",
    "def getKeys(nc_fid):\n",
    "    '''Get the variables names in the NetCDF file'''\n",
    "    keys=[]\n",
    "    nc_vars = [var for var in nc_fid.variables]\n",
    "    for vars in nc_vars:\n",
    "        keys.append(getattr(nc_fid.variables[vars],'long_name'))\n",
    "    return keys\n",
    "        \n",
    "def getMFNcVar(nc_fid, keys):\n",
    "    ''' Extract variables from a dataset across multiple netCDF files.\n",
    "    \n",
    "    This function gets the variable contained in a netCDF file \n",
    "    and return them into Python nested dictionaries. The first\n",
    "    dictionary's key contains the longname, while the\n",
    "    second dictionary contains values, standard name (CF),\n",
    "    units and the missing data flag.\n",
    "    \n",
    "    Args:\n",
    "        nc_files (list): A list of netCDF files containing the dataset\n",
    "        keys (list): A list of keys to fetch the variables according\n",
    "            to the CF standard\n",
    "    \n",
    "    Returns:\n",
    "        dict_out (dict): A dictionary containing the standard names as keys and\n",
    "            the associated data as values.\n",
    "    '''\n",
    "    \n",
    "    nc_vars = [var for var in nc_fid.variables]\n",
    "    \n",
    "    #Make empty lists to collect the info\n",
    "    #longname (should be using the CF conventions)\n",
    "    nc_vars_longname=[]\n",
    "    #Units\n",
    "    nc_vars_units=[]\n",
    "    # Get the standard name\n",
    "    nc_vars_standardname=[]\n",
    "    #Corrections\n",
    "    nc_vars_scale_factor=[]\n",
    "    nc_vars_add_offset=[]\n",
    "    #Missing values\n",
    "    nc_vars_missing_value=[]\n",
    "    \n",
    "    for vars in nc_vars:\n",
    "        if 'long_name' in nc_fid.variables[vars].ncattrs():\n",
    "            nc_vars_longname.append(getattr(nc_fid.variables[vars],'long_name'))\n",
    "        else:\n",
    "            nc_vars_longname.append(vars)\n",
    "        if 'units' in nc_fid.variables[vars].ncattrs():\n",
    "            nc_vars_units.append(getattr(nc_fid.variables[vars],'units'))\n",
    "        else:\n",
    "            nc_vars_units.append('NA')\n",
    "        if 'standard_name' in nc_fid.variables[vars].ncattrs():\n",
    "            nc_vars_standardname.append(getattr(nc_fid.variables[vars],'standard_name'))\n",
    "        else:\n",
    "            nc_vars_standardname.append(\"NA\")    \n",
    "        if 'scale_factor' in nc_fid.variables[vars].ncattrs():\n",
    "            nc_vars_scale_factor.append(getattr(nc_fid.variables[vars],'scale_factor'))\n",
    "        else:\n",
    "            nc_vars_scale_factor.append(1)\n",
    "        if 'add_offset' in nc_fid.variables[vars].ncattrs():\n",
    "            nc_vars_add_offset.append(getattr(nc_fid.variables[vars],'add_offset'))\n",
    "        else:\n",
    "            nc_vars_add_offset.append(0) \n",
    "        if 'missing_value' in nc_fid.variables[vars].ncattrs(): \n",
    "            nc_vars_missing_value.append(getattr(nc_fid.variables[vars],'missing_value'))\n",
    "        else:\n",
    "            nc_vars_missing_value.append('NA')\n",
    "    # Check for the list against the desired variables and output.\n",
    "    dict_out ={}\n",
    "    for name in nc_vars_longname:\n",
    "        if name in keys:\n",
    "            f = {'values':[],'units':[],'missing_value':[], 'standard_name':{}}\n",
    "            idx = nc_vars_longname.index(name)\n",
    "            f['values']=(nc_fid.variables[nc_vars[idx]][:]*nc_vars_scale_factor[idx])\\\n",
    "                +nc_vars_add_offset[idx]\n",
    "            f['units']=nc_vars_units[idx]\n",
    "            f['missing_value'] = nc_vars_missing_value[idx]\n",
    "            f['standard_name'] = nc_vars_standardname[idx]\n",
    "            dict_out[name] = f\n",
    "    \n",
    "    return dict_out\n",
    "\n",
    "root = \"/Volumes/Data HD/Documents/MINT/WINGS/NetCDFWings\"\n",
    "files = [\"Oct2010.nc\",\"Nov2010.nc\",\"Dec2010.nc\"]\n",
    "\n",
    "file_names =[]\n",
    "for name in files:\n",
    "    file_names.append(root+\"/\"+name)\n",
    "    \n",
    "#Open the file and get the keys for this example\n",
    "nc_fid = MFDataset(file_names)\n",
    "keys = getKeys(nc_fid)\n",
    "dict_out=getMFNcVar(nc_fid,keys)\n",
    "\n",
    "with open(\"pickle1.p\",\"wb\") as handle:\n",
    "    pickle.dump(dict_out, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name='adjusttime'> adjustTime </a>\n",
    "\n",
    "Time coordinate values pose a special challeneg to netCDF users. Most metadata standards (such as CF) specify that time should be measured relative to a fixed data using a certain calendar, with units specified like **hours since YY-MM-DD hh:mm:ss**. These units can be awkward to deal with, without a utility to convert the valuesto and from calendar dates. The function called `num2date` and `date2num` are provided with the `netCDF4` package to do just that.\n",
    "\n",
    "`num2date` converts numeric values of time in the specified **units** and **calendar** to datetime objects, and `date2num` does the reverse.\n",
    "\n",
    "- `units`: a string of the form **&lt;time units&gt; since &lt;reference time&gt;** describing the time units. **&lttime units&gh;** can be days, hours, minutes, seconds, milliseconds, or microseconds. **&lt;reference time&gt;** is the time origin.\n",
    "- `calendar`: describes the calendar used in the time calculations. All the values currently defined in the [CF metadata convention](http://cfconventions.org/) are valid calendars: **'standard'**, **'gregorian'**, **'proleptic_gregorian'**, **'noleap'**, **'365_day'**, **'360_day'**, **'julian'**, **'all_leap'**, **'366_day'**. Default is **'standard'**, which is a mixed Julian/Gregorian calendar.\n",
    "\n",
    "([source](http://unidata.github.io/netcdf4-python/#section7))\n",
    "\n",
    "- Inputs: pickle file\n",
    "- Outputs: pickle file\n",
    "- parameters: one of the valid calendars described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param = 'standard'\n",
    "\n",
    "import pickle\n",
    "from datetime import datetime, timedelta\n",
    "from netCDF4 import num2date, date2num\n",
    "\n",
    "with open(\"pickle1.p\", 'rb') as handle:\n",
    "    dict_out = pickle.load(handle)\n",
    "\n",
    "dates = num2date(dict_out['time']['values'][:],dict_out['time']['units'])\n",
    "dict_out['dates']={'values':dates, 'calendar':param, 'units':'NA'}\n",
    "\n",
    "with open(\"pickle2.p\",\"wb\") as handle:\n",
    "    pickle.dump(dict_out, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name='selectVar'> selectVar </a>\n",
    "\n",
    "This component selects the variables in the dictionary that correspond to the model variables. If model variables are not present, send a warning.\n",
    "\n",
    "- Inputs: pickle file from previous step, a text file containing the list of variables\n",
    "- Outputs: warning file. This file will be needed for \n",
    "- Parameters: none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "f2 = open('modelVar.txt','r') \n",
    "var = f2.readlines()\n",
    "var = [x.strip() for x in var]\n",
    "\n",
    "with open(\"pickle2.p\", 'rb') as handle:\n",
    "    dict_out = pickle.load(handle)\n",
    "\n",
    "warningsVar = []\n",
    "for item in var:\n",
    "    if item not in dict_out.keys():\n",
    "       warningsVar.append(item)\n",
    "\n",
    "f3 = open('warnings.txt','w')\n",
    "for item in warningsVar:\n",
    "   f3.write(\"%s\\n\" % item)            \n",
    "f3.close()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name='calculateRH'> calculateRH </a>\n",
    "\n",
    "This functions calculates relative humidity from temperature and dew point temperature. Note that one would have to know to use the temperature at the same atmospheric level (2m here) for the calculation.\n",
    "\n",
    "Relative humidity can be calculate from temperature and dewpoint temperature. In the query, care should be taken as to choose temperature taken at the same elevation. In this particular example, we use `2 metre temperature` and `2 metre dewpoint temperature`.\n",
    "\n",
    "Relative humidity can then be calculated as follows:\n",
    "\n",
    "$RH=100\\times\\frac{e^{\\frac{17.625\\times TD}{243.04+TD}}}{e^{\\frac{17.625\\times T}{243.04+T}}}$\n",
    "\n",
    "where T (temperature) and TD (dewpoint temperature) are in deg C.\n",
    "\n",
    "- Input: pickle file\n",
    "- Output: pickle file\n",
    "- Parameters: None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "with open(\"pickle2.p\", 'rb') as handle:\n",
    "    dict_out = pickle.load(handle)\n",
    "    \n",
    "TD = np.array(dict_out['2 metre dewpoint temperature']['values'])\n",
    "T = np.array(dict_out['2 metre temperature']['values'])\n",
    "RH = 100*(np.exp((17.625*TD)/(243.04+TD))/np.exp((17.625*T)/(243.04+T)))\n",
    "\n",
    "dict_out['Relative Humidity']={'values':RH,'units':'NA'} \n",
    "\n",
    "with open(\"pickle3.p\",\"wb\") as handle:\n",
    "    pickle.dump(dict_out, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name='calculatewind'> calculateWind </a>\n",
    "\n",
    "Wind speed can be calculated from the u-wind and v-wind components. TOPOFLOW also calls for the reference height which is contained in the name of the variables: `10 metre U wind component` and `10 metre V wind component`. As for relative humidity, one would have to use wind components at the same reference height (here 10m). The reference height is an input to TOPOFLOW and needs to be included in the dictionary.\n",
    "\n",
    "Wind speed can be calculated as follows:\n",
    "\n",
    "$WS = \\sqrt{U^{2}+V^{2}}$\n",
    "\n",
    "- Input: pickle file\n",
    "- Output: pickle file\n",
    "- Parameters: None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "with open(\"pickle3.p\", 'rb') as handle:\n",
    "    dict_out = pickle.load(handle)\n",
    "    \n",
    "U = np.array(dict_out['10 metre U wind component']['values'])\n",
    "V = np.array(dict_out['10 metre V wind component']['values'])\n",
    "\n",
    "W = np.sqrt(U**2+V**2)\n",
    "\n",
    "dict_out['Wind Speed']={'values':W,'units':dict_out['10 metre V wind component']['units']}\n",
    "\n",
    "#Get the wind height\n",
    "s = '10 metre U wind component'\n",
    "m = re.findall(r'\\d+', s)[0]\n",
    "dict_out['Wind reference height']={'values':int(m),'units':dict_out['10 metre V wind component']['units']}\n",
    "\n",
    "with open(\"pickle4.p\",\"wb\") as handle:\n",
    "   pickle.dump(dict_out, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name='amount'> amountToRate </a>\n",
    "\n",
    "Precipitation is given as total amount in the reanalysis dataset. TOPOFLOW takes a rate input of mm/hr, which requires knowing the time step of the data (in this case, 3hr). The time step would be given upon dowload and should be stored in the data catalog. Assumed known in this example.\n",
    "\n",
    "- Input: pickle file\n",
    "- Output: pickle file\n",
    "- Parameters: None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "with open(\"pickle4.p\", 'rb') as handle:\n",
    "    dict_out = pickle.load(handle)\n",
    "    \n",
    "precip_rate = 1000*np.array(dict_out['Total precipitation']['values'])/3\n",
    "\n",
    "dict_out['Precipitation rate'] = {'values':precip_rate.tolist(), \\\n",
    "                                  'units':'mm/hr','notes':\\\n",
    "                                  'converted from amount, Total precipitation'}\n",
    "\n",
    "with open(\"pickle5.p\",\"wb\") as handle:\n",
    "    pickle.dump(dict_out, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name='complete'> completeCheck </a>\n",
    "\n",
    "This component ensures that all the proper variables are present in the pickled file. Will raise a `SystemExit` error if not every variable is present.\n",
    "\n",
    "- Input: pickle file\n",
    "- Output: None\n",
    "- Parameters: None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys\n",
    "\n",
    "with open(\"pickle5.p\", 'rb') as handle:\n",
    "    dict_out = pickle.load(handle)\n",
    "    \n",
    "f2 = open(root+'/modelVar.txt','r') \n",
    "var = f2.readlines()\n",
    "var = [x.strip() for x in var]\n",
    "\n",
    "for item in var:\n",
    "    if item not in dict_out.keys():\n",
    "        sys.exit('variables are missing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## <a name='units'> adjustUnits </a>\n",
    "\n",
    "This component adjust the units. We will need to have a library of units transformation. For this example, the units for the modelVarUnits file were made to match that present in the data file except for pressure. Note that these units do not correspond to the ones in Topoflow (especially regarding temperature).\n",
    "\n",
    "- Inputs: Pickled file\n",
    "- Outputs: Pickled file\n",
    "- Parameters: None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting Surface pressure units...\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"pickle5.p\", 'rb') as handle:\n",
    "    dict_out = pickle.load(handle)\n",
    "    \n",
    "f2 = open('modelVar.txt','r') \n",
    "var = f2.readlines()\n",
    "var = [x.strip() for x in var]\n",
    "\n",
    "f3 =  open('modelVarUnits.txt','r')\n",
    "units = f3.readlines()\n",
    "units = [x.strip() for x in units]\n",
    "\n",
    "for idx, item in enumerate(var):\n",
    "    dataUnits = dict_out[item]['units']\n",
    "    if dataUnits != units[idx]:\n",
    "        print(\"Adjusting \"+item+' units...')\n",
    "        P = dict_out['Surface pressure']['values']/100\n",
    "        dict_out['Surface pressure']={'values':P,'units':'mbar','notes':'units have been converted'}\n",
    "        \n",
    "with open(\"pickle6.p\",\"wb\") as handle:\n",
    "    pickle.dump(dict_out, handle, protocol=pickle.HIGHEST_PROTOCOL)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=format> adjustFormat </a>\n",
    "\n",
    "This component produces the binary text files for use by Topoflow.\n",
    "\n",
    "- Input: Pickled file\n",
    "- Outputs: Collection of text files\n",
    "- Parameters: None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "with open(\"pickle6.p\", 'rb') as handle:\n",
    "    dict_out = pickle.load(handle)\n",
    "\n",
    "f2 = open('modelVar.txt','r') \n",
    "var = f2.readlines()\n",
    "var = [x.strip() for x in var]\n",
    "\n",
    "for item in var:\n",
    "    dataValues = dict_out[item]['values']\n",
    "    dataValues = np.float32(dataValues)\n",
    "    filename = item+'.txt'\n",
    "    f = open(filename,'wb')\n",
    "    #dataValues.byteswap(True)\n",
    "    dataValues.tofile(f)\n",
    "    f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
